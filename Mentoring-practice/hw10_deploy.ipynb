{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6831fe55",
      "metadata": {
        "id": "6831fe55"
      },
      "source": [
        "# KV Cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f29b7f3c",
      "metadata": {
        "id": "f29b7f3c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5045cc82",
      "metadata": {
        "id": "5045cc82"
      },
      "source": [
        "Представим, что у нас есть очень простая мини-LLM:\n",
        "1. Она эмбеддит токены\n",
        "2. Считает аттеншн (обычный, не multihead) токенов друг с другом с causal mask (не смотрит в будущее!)\n",
        "3. После этого выходы attention подаются в линейный слой для получения распределеняи по словарю\n",
        "\n",
        "На примере такой модели давайте попробуем имплементировать KV-Cache.\n",
        "\n",
        "Ниже за вас написан метод forward - этот метод это обычный forward нейросети, который считает attention всех токенов со всеми токенами.\n",
        "\n",
        "Вам же нужно имплементировать метод forward_kv_cache, который принимает:\n",
        "* x - тензор размерности \\[batch, seq_len = 1\\]\n",
        "* prev_output - выход модели с предыдущего шага типа Output\n",
        "\n",
        "Метод forward_kv_cache должен выполнять следующие действия:\n",
        "1. Эмбеддинг токена x\n",
        "2. Проекция x в QKV\n",
        "3. Расширение k_cache и v_cache из prev_ouptut k/v проекциями x\n",
        "4. Подсчет аттеншена между q_x и k_cache и v_cache\n",
        "5. Конкатенация аттеншена в prev_output.attention_weights\n",
        "6. Возврат logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ce42ab63",
      "metadata": {
        "id": "ce42ab63",
        "outputId": "be247e8c-81ef-427e-8934-4d111c544d7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before generation tensor([[1, 3, 0]])\n",
            "After generation no cache tensor([[1, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0]])\n",
            "After generation kv cache tensor([[1, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0]])\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class Output:\n",
        "    logits: torch.Tensor = None\n",
        "    k_cache: torch.Tensor = None\n",
        "    v_cache: torch.Tensor = None\n",
        "    attn_weights: torch.Tensor = None\n",
        "\n",
        "\n",
        "\n",
        "class SimpleAttentionLLM(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.W_Q = nn.Linear(d_model, d_model)\n",
        "        self.W_K = nn.Linear(d_model, d_model)\n",
        "        self.W_V = nn.Linear(d_model, d_model)\n",
        "        self.lin = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        q = self.W_Q(x)\n",
        "        k = self.W_K(x)\n",
        "        v = self.W_V(x)\n",
        "\n",
        "        attn_scores = torch.matmul(q, k.permute(0, 2, 1))\n",
        "        mask = torch.tril(torch.ones_like(attn_scores))\n",
        "        attn_scores = attn_scores.masked_fill(~mask.bool(), -torch.inf)\n",
        "        attn_weights = torch.softmax(attn_scores, dim=2)\n",
        "        weights_V = torch.matmul(attn_weights, v)\n",
        "        logits = self.lin(weights_V)\n",
        "        return Output(\n",
        "            logits=logits,\n",
        "            k_cache=k,\n",
        "            v_cache=v,\n",
        "            attn_weights=attn_weights # batch, seq_len, seq_len\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward_kv_cache(self, x, prev_output):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # 1. Проецируем x в q, k, v\n",
        "        q = self.W_Q(x) # (B, 1, d_model)\n",
        "        k = self.W_K(x) # (B, 1, d_model)\n",
        "        v = self.W_V(x) # (B, 1, d_model)\n",
        "\n",
        "\n",
        "        # берем старый кэш\n",
        "        k_cache = prev_output.k_cache\n",
        "        v_cache = prev_output.v_cache\n",
        "\n",
        "        # расширяем его состояниями k, v последнего токена\n",
        "        # с помощью torch.cat\n",
        "        k_cache_new = torch.cat([k_cache, k], dim=1) # (B, old_len+1, d_model)\n",
        "        v_cache_new = torch.cat([v_cache, v], dim=1) # (B, old_len+1, d_model)\n",
        "\n",
        "        # считаем attention_score, то есть матричное умножение между q и k_cache_new\n",
        "        attn_scores = q @ k_cache_new.permute(0, 2, 1) # (B, 1, old_len+1)\n",
        "\n",
        "\n",
        "        # считаем softmax\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1) # (B, 1, old_len+1)\n",
        "        # домножаем softmax на V\n",
        "\n",
        "        weights_V = attn_weights @ v_cache_new # (B, 1, d_model)\n",
        "        logits = self.lin(weights_V)\n",
        "\n",
        "        batch = x.size(0)\n",
        "        seq_len = k_cache.size(1)\n",
        "\n",
        "        attn_weights_old = prev_output.attn_weights\n",
        "        zeros_right = torch.zeros(batch, seq_len, 1)\n",
        "        # добавляем нули в аттеншене так, чтобы у старых токенов был нулевой аттеншн на новый токен\n",
        "        attn_weights_all = torch.cat((attn_weights_old, zeros_right), dim=2)\n",
        "        # Добавляем аттеншн текущего нового токена по старым\n",
        "        attn_weights_all = torch.cat((attn_weights_all, attn_weights), dim=1)\n",
        "\n",
        "        return Output(\n",
        "            logits=logits,\n",
        "            k_cache=k_cache_new,\n",
        "            v_cache=v_cache_new,\n",
        "            attn_weights=attn_weights_all\n",
        "        )\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "batch_size = 1\n",
        "seq_len = 3\n",
        "d_model = 128\n",
        "vocab_size = 7\n",
        "\n",
        "layer = SimpleAttentionLLM(d_model, vocab_size)\n",
        "for param in layer.parameters():\n",
        "    nn.init.normal_(param)\n",
        "\n",
        "x = torch.randint(0, 7, (batch_size, seq_len))\n",
        "x_copy = x.clone()\n",
        "\n",
        "print(\"Before generation\", x)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(10):\n",
        "        outputs = layer(x)\n",
        "        logits = outputs.logits\n",
        "        # берем последний токен, т.к. по нему предсказываем!\n",
        "        next_token = logits[:, -1].argmax(dim=1, keepdim=True)\n",
        "        x = torch.cat((x, next_token), dim=1) # добавляем новый токен по размерности seq_len\n",
        "\n",
        "no_cache_output = outputs\n",
        "print(\"After generation no cache\", x)\n",
        "\n",
        "\n",
        "x = x_copy.clone()\n",
        "final_tokens = x.clone()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # prefill\n",
        "    outputs = layer(x)\n",
        "    logits = outputs.logits\n",
        "    # берем последний токен, т.к. по нему предсказываем!\n",
        "    next_token = logits[:, -1].argmax(dim=1, keepdim=True)\n",
        "    # обратите внимание, что раньше было 10 шагов!\n",
        "    final_tokens = torch.cat((final_tokens, next_token), dim=1)\n",
        "    for i in range(9):\n",
        "        outputs = layer.forward_kv_cache(next_token, outputs)\n",
        "        next_token = outputs.logits[:, -1].argmax(dim=1, keepdim=True)\n",
        "        final_tokens = torch.cat((final_tokens, next_token), dim=1)\n",
        "\n",
        "print(\"After generation kv cache\", final_tokens)\n",
        "\n",
        "cache_outputs = outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be62b506",
      "metadata": {
        "id": "be62b506"
      },
      "source": [
        "Выведем матрицы attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "305f232d",
      "metadata": {
        "id": "305f232d",
        "outputId": "52188742-c8e9-42c9-a5ab-51e7f2be4246"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Attention kv cache')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "axes[0].imshow(no_cache_output.attn_weights[0])\n",
        "axes[0].set_title(\"Attention no cache\")\n",
        "axes[1].imshow(cache_outputs.attn_weights[0])\n",
        "axes[1].set_title(\"Attention kv cache\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "326b101e",
      "metadata": {
        "id": "326b101e"
      },
      "outputs": [],
      "source": [
        "!pip install vllm triton"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e45fc6",
      "metadata": {
        "id": "76e45fc6"
      },
      "source": [
        "По возможности данное задание необходимо выполнять на сервере, чтобы было удобно запускать параллельно фреймворк и нагрузочное тестирование. Для удобства работы в jupyter сделан следующий трюк"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2b6fba6",
      "metadata": {
        "id": "d2b6fba6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import multiprocessing\n",
        "import subprocess\n",
        "\n",
        "def start_vllm_server():\n",
        "    # This function will run the `vllm` server command\n",
        "    cmd = [\"vllm\", \"serve\", \"unsloth/gemma-2b-it\", \"--dtype\", \"half\"]\n",
        "    subprocess.run(cmd)\n",
        "\n",
        "\n",
        "server_process = multiprocessing.Process(target=start_vllm_server)\n",
        "server_process.start()\n",
        "time.sleep(60)\n",
        "print(\"we are probably ready\")\n",
        "\n",
        "import requests\n",
        "\n",
        "r = requests.post(\"http://localhost:8000/v1/completions\", json={\n",
        "                  \"model\": \"unsloth/gemma-2b-it\",\n",
        "                  \"prompt\": \"Hello there\",\n",
        "                  \"max_tokens\": 20,\n",
        "                  \"temperature\": 0.8\n",
        "              })\n",
        "print(r.json())\n",
        "print(r.json()[\"choices\"][0][\"text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad31f5df",
      "metadata": {
        "id": "ad31f5df"
      },
      "source": [
        "# Нагрузочное тестирование\n",
        "\n",
        "Необходимо узнать, сколько запросов в секунду выдержит VLLM сервинг модели при ограничении latency в 5 секунд.\n",
        "Можно использовать самописную функцию через multiprocessing/threading, можно использовать любой готовый инструмент.\n",
        "\n",
        "В качестве пейлоадов предлагается брать тексты длины 100-128 и генерировать к ним не более 10 токенов. Сами пейлоады можно взять из любого датасета, например https://huggingface.co/datasets/Intel/orca_dpo_pairs.\n",
        "\n",
        "Об аргументах vllm serve можно почитать в документации https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html\n",
        "\n",
        "\n",
        "Дополнительный плюс, если сможете посчитать на этом пейлоаде ttft - time to first token, то есть сколько занимает prefill стадия генерации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e05e253",
      "metadata": {
        "id": "1e05e253"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "08c334b3",
      "metadata": {
        "id": "08c334b3"
      },
      "source": [
        "# Часть 2\n",
        "Далее предоставлено 2 варианта выполнения задания.\n",
        "\n",
        "## Вариант 1. Квантизация\n",
        "Квантизируйте модель в VLLM любым доступным способом, напишите, как сократились затраты памяти и как изменилась скорость инференса. Обязательно укажите, на какой видеокарте проводились замеры!\n",
        "Не забудьте про то, что квантизировать можно и kv cache.\n",
        "\n",
        "Внимательно проверьте и убедитесь, что ваш ускоритель поддержан в https://docs.vllm.ai/en/latest/quantization/supported_hardware.html\n",
        "\n",
        "## Вариант 2. Батчевалка\n",
        "Предлагается написать сервер на питоне, который поддерживал бы батчевание запросов.\n",
        "\n",
        "Сервер принимает POST запрос с телом вида\n",
        "\n",
        "```json\n",
        "{\"text\": \"Hello there\"}\n",
        "```\n",
        "\n",
        "\n",
        "Необходимо написать сервер, который:\n",
        "1. Имел бы возможность работать с несколькими клиентами за раз (не блокировался бы на обработку одного запроса). Для этого можно использовать async, gevent, треды и т.д.\n",
        "2. Использовал бы батчовую обработку следующим образом:\n",
        "если пришло несколько запросов (для примера 2)\n",
        "\n",
        "```json\n",
        "запрос 1\n",
        "{\"text\": \"Hello there \"}\n",
        "запрос 2\n",
        "{\"text\": \"handsome\"}\n",
        "```\n",
        "\n",
        "то каждый клиент получал бы в ответ конкатенацию этих запросов (в произвольном порядке), т.е. оба клиента получили бы ответ\n",
        "```json\n",
        "{\"text\": \"Hello there handsome\"}\n",
        "или\n",
        "{\"text\": \"handsomeHello there \"}\n",
        "```\n",
        "\n",
        "Сервер должен иметь 2 конфигурируемых параметра:\n",
        "1. Максимальный размер батча, который он может обработать\n",
        "2. Максимальное время ожидания, которое ждет сэмпл перед обработкой. Т.е. если у нас батч размера 5, а у нас всего один сэмпл, и прошло максимальное время ожидания - этот сэмпл попадает в батч один и обрабатывается один.\n",
        "\n",
        "Для хранения данных в очереди можно использовать queue.Queue или любой другой удобный способ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe94205",
      "metadata": {
        "id": "1fe94205"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
